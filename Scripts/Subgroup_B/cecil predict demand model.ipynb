{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand prediction for theme parks (specific case of USS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import simpy\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "os.chdir(\"C:/Users/THAI LOW Jin Yang/data-science-guest-experience/Scripts/Subgroup_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets\n",
    "### Load survey data\n",
    "\n",
    "What the function does:\n",
    "- renames question columns for easier reference\n",
    "- converting wait times to numerical values, taking the median/mean of the range\n",
    "- adding synthetic event column: USS only has 1 notable special event which is HHN, which is assigned to visitors that came during October - December season. Otherwise, the column is assigned as none. For visitors that forgot the timeline in which they visited, a random value will be assigned.\n",
    "- handling long wait times: splits attractions that have long wait times into separate observations and assign a baseline wait time which is 90 minutes, for those that felt queueing time was not worth the experience, and 75 for those that do. \n",
    "- normalise guest satisfaction score\n",
    "- process timestamp and extracting date features\n",
    "- filters for valid attractions, which only keeps popular attractions like: revenge of the mummy, cylon, transformers, etc\"\n",
    "- ensuring required columns are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Attraction  Wait_Time          Event  \\\n",
      "4   Sesame Street Spaghetti Space Chase       37.5           None   \n",
      "5                  Revenge of the Mummy       37.5           None   \n",
      "6                  Revenge of the Mummy       37.5           None   \n",
      "8   Sesame Street Spaghetti Space Chase       37.5           None   \n",
      "11                 Revenge of the Mummy       37.5  Special Event   \n",
      "\n",
      "    Guest_Satisfaction_Score Which part of the year did you visit USS?  \\\n",
      "4                       0.50                   Can't recall / Not sure   \n",
      "5                       0.75                   Can't recall / Not sure   \n",
      "6                       0.50                   Can't recall / Not sure   \n",
      "8                       0.75                        October - December   \n",
      "11                      0.25                   Can't recall / Not sure   \n",
      "\n",
      "   Did you purchase the Express Pass?  \\\n",
      "4                                  No   \n",
      "5                                  No   \n",
      "6                                  No   \n",
      "8                                  No   \n",
      "11                                 No   \n",
      "\n",
      "   What was the main purpose of your visit?  Who did you visit USS with?  \\\n",
      "4                             Family outing  Family (including children)   \n",
      "5                             Family outing         Family (adults only)   \n",
      "6                          Social gathering                      Friends   \n",
      "8                          Social gathering                      Friends   \n",
      "11                         Social gathering                      Friends   \n",
      "\n",
      "   Which age group do you belong to?              Season  \n",
      "4                  18 - 24 years old  October - December  \n",
      "5                  18 - 24 years old  October - December  \n",
      "6                  18 - 24 years old    July - September  \n",
      "8                  18 - 24 years old  October - December  \n",
      "11                 18 - 24 years old    July - September  \n"
     ]
    }
   ],
   "source": [
    "def load_survey_data(file_path=\"../../data/survey.csv\"):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses survey data from survey.csv, extracting seasonal information\n",
    "    and normalizing satisfaction scores. Timestamp is removed in favor of seasonal tagging.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the survey CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed survey data with 'Season' column added.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"{file_path} not found. Please provide the survey dataset.\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"On a scale of 1-5, how would you rate your overall experience at USS?\": \"Guest_Satisfaction_Score\",\n",
    "        \"How long did you wait in line for rides on average during your visit?\": \"Wait_Time\",\n",
    "        \"Which ride or attraction was your favourite?\": \"Attraction\"\n",
    "    })\n",
    "\n",
    "    # Map wait times to numerical estimates\n",
    "    wait_time_mapping = {\n",
    "        \"Less than 15 mins\": 10,\n",
    "        \"15-30 mins\": 22.5,\n",
    "        \"30-45 mins\": 37.5,\n",
    "        \"45 mins - 1 hr\": 52.5,\n",
    "        \"More than 1 hr\": 75\n",
    "    }\n",
    "    df[\"Wait_Time\"] = df[\"Wait_Time\"].map(wait_time_mapping).fillna(37.5)\n",
    "\n",
    "    # Generate synthetic Event column\n",
    "    np.random.seed(42)\n",
    "    df[\"Event\"] = np.random.choice(['None', 'Special Event'], size=len(df), p=[0.8, 0.2])\n",
    "\n",
    "    # Handle optional long wait experience data (as before)\n",
    "    long_wait_df = pd.DataFrame()\n",
    "    if 'Did you experience any rides with longer-than-expected wait times? If yes, which ride(s)?' in df.columns:\n",
    "        long_wait_rides = df['Did you experience any rides with longer-than-expected wait times? If yes, which ride(s)?'].str.split(', ', expand=True).stack().reset_index()\n",
    "        long_wait_rides.columns = ['original_index', 'split_index', 'Attraction']\n",
    "        long_wait_rides = long_wait_rides[long_wait_rides['Attraction'].notna()]\n",
    "\n",
    "        queue_worth_col = 'Did you feel that overall, the queuing time was worth the experience of the attraction? '\n",
    "        unpleasant_col = 'What made your experience with this ride or attraction unpleasant? '\n",
    "\n",
    "        wait_time_adjusted = []\n",
    "        for idx in long_wait_rides['original_index']:\n",
    "            base_wait = 75\n",
    "            if queue_worth_col in df.columns and df[queue_worth_col].iloc[idx] == 'No':\n",
    "                base_wait = 90\n",
    "            if unpleasant_col in df.columns and pd.notna(df[unpleasant_col].iloc[idx]):\n",
    "                if 'long wait' in str(df[unpleasant_col].iloc[idx]).lower():\n",
    "                    base_wait += 15\n",
    "            wait_time_adjusted.append(base_wait)\n",
    "\n",
    "        long_wait_df = pd.DataFrame({\n",
    "            'Attraction': long_wait_rides['Attraction'],\n",
    "            'Event': df['Event'].iloc[long_wait_rides['original_index']].values,\n",
    "            'Wait_Time': wait_time_adjusted,\n",
    "            'Guest_Satisfaction_Score': df['Guest_Satisfaction_Score'].iloc[long_wait_rides['original_index']].values,\n",
    "            'Which part of the year did you visit USS?': df['Which part of the year did you visit USS?'].iloc[long_wait_rides['original_index']].values,\n",
    "            'Did you purchase the Express Pass?': df['Did you purchase the Express Pass?'].iloc[long_wait_rides['original_index']].values if 'Did you purchase the Express Pass?' in df.columns else [None] * len(long_wait_rides),\n",
    "            'What was the main purpose of your visit?': df['What was the main purpose of your visit?'].iloc[long_wait_rides['original_index']].values if 'What was the main purpose of your visit?' in df.columns else [None] * len(long_wait_rides),\n",
    "            'Who did you visit USS with?': df['Who did you visit USS with?'].iloc[long_wait_rides['original_index']].values if 'Who did you visit USS with?' in df.columns else [None] * len(long_wait_rides),\n",
    "            'Which age group do you belong to?': df['Which age group do you belong to?'].iloc[long_wait_rides['original_index']].values if 'Which age group do you belong to?' in df.columns else [None] * len(long_wait_rides)\n",
    "        })\n",
    "\n",
    "    base_df = df[['Attraction', 'Wait_Time', 'Event', 'Guest_Satisfaction_Score',\n",
    "                  'Which part of the year did you visit USS?', 'Did you purchase the Express Pass?',\n",
    "                  'What was the main purpose of your visit?', 'Who did you visit USS with?',\n",
    "                  'Which age group do you belong to?']].copy()\n",
    "\n",
    "    df_combined = pd.concat([base_df, long_wait_df], ignore_index=True)\n",
    "\n",
    "    # Normalize Guest Satisfaction\n",
    "    df_combined[\"Guest_Satisfaction_Score\"] = pd.to_numeric(df_combined[\"Guest_Satisfaction_Score\"], errors=\"coerce\")\n",
    "    df_combined[\"Guest_Satisfaction_Score\"] = (\n",
    "        (df_combined[\"Guest_Satisfaction_Score\"] - df_combined[\"Guest_Satisfaction_Score\"].min()) /\n",
    "        (df_combined[\"Guest_Satisfaction_Score\"].max() - df_combined[\"Guest_Satisfaction_Score\"].min())\n",
    "    )\n",
    "\n",
    "    # Assign season based on user input or synthetic if 'Can't recall'\n",
    "    def assign_season(row):\n",
    "        season = row['Which part of the year did you visit USS?']\n",
    "        if season != \"Can't recall / Not sure\":\n",
    "            return season\n",
    "        return np.random.choice(\n",
    "            [\"July - September\", \"October - December\", \"January - March\", \"April - June\"],\n",
    "            p=[0.6, 0.3, 0.05, 0.05]\n",
    "        )\n",
    "\n",
    "    df_combined['Season'] = df_combined.apply(assign_season, axis=1)\n",
    "\n",
    "    # Filter valid attractions\n",
    "    valid_attractions = [\n",
    "        \"Revenge of the Mummy\",\n",
    "        \"Battlestar Galactica: CYLON\",\n",
    "        \"Transformers: The Ride\",\n",
    "        \"Puss In Boots' Giant Journey\",\n",
    "        \"Sesame Street Spaghetti Space Chase\"\n",
    "    ]\n",
    "    df_combined = df_combined[df_combined['Attraction'].isin(valid_attractions)]\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "\n",
    "df_survey = load_survey_data()\n",
    "print(df_survey.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IOT data (optional, to answer question 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp                    Attraction    Age_Group  Gender  \\\n",
      "0 2024-12-02 17:13:25  Puss In Boots' Giant Journey       Senior  Female   \n",
      "1 2024-12-01 13:26:11  Puss In Boots' Giant Journey        Adult    Male   \n",
      "2 2024-11-29 07:52:28  Puss In Boots' Giant Journey        Child    Male   \n",
      "3 2024-08-01 16:39:11  Puss In Boots' Giant Journey  Young Adult    Male   \n",
      "4 2024-05-31 18:22:35          Revenge of the Mummy        Child  Female   \n",
      "\n",
      "  Loyalty_Member  Check_In_Time  Check_Out_Time  Step_Count  \\\n",
      "0             No              9              14       12775   \n",
      "1             No             13              16       14102   \n",
      "2             No             12              17       13212   \n",
      "3             No              9              16       13017   \n",
      "4             No             12              17        9916   \n",
      "\n",
      "   Transaction_Amount  Guest_Satisfaction_Score  Average_Queue_Time  \\\n",
      "0                 171                  3.945533                  51   \n",
      "1                 217                  4.292259                  73   \n",
      "2                 210                  3.121087                  64   \n",
      "3                 250                  1.186939                  89   \n",
      "4                 182                  2.711499                  60   \n",
      "\n",
      "   Number_of_People_in_Queue  Temperature  Rainfall   Humidity day_of_week  \\\n",
      "0                         92    27.022338  0.000116  81.321270      Monday   \n",
      "1                         50    29.069799 -0.000024  85.896144      Sunday   \n",
      "2                        179    26.446438  0.000404  89.083054      Friday   \n",
      "3                         71    26.442944 -0.000031  85.951381    Thursday   \n",
      "4                         67    27.798251  0.000373  82.945439      Friday   \n",
      "\n",
      "   is_weekend  is_popular_attraction  \n",
      "0       False                  False  \n",
      "1        True                  False  \n",
      "2       False                  False  \n",
      "3       False                  False  \n",
      "4       False                   True  \n"
     ]
    }
   ],
   "source": [
    "def load_iot_data(file_path=\"../../data/synthetic_iot_data.csv\"):\n",
    "    \"\"\"\n",
    "    Loads synthetic IoT data for demand prediction, adding day_of_week, is_weekend, and is_popular_attraction features.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the synthetic IoT CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed IoT data.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: IoT data file {file_path} not found. Skipping IoT data integration.\")\n",
    "        return None\n",
    "\n",
    "    df_iot = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert Timestamp to datetime\n",
    "    df_iot['Timestamp'] = pd.to_datetime(df_iot['Timestamp'])\n",
    "\n",
    "    # Add day_of_week feature\n",
    "    df_iot['day_of_week'] = df_iot['Timestamp'].dt.day_name()\n",
    "\n",
    "    # Add is_weekend feature (True for Saturday and Sunday)\n",
    "    df_iot['is_weekend'] = df_iot['day_of_week'].isin([\"Saturday\", \"Sunday\"])\n",
    "\n",
    "    # Define popular attractions\n",
    "    POPULAR_ATTRACTIONS = {\"Revenge of the Mummy\", \"Battlestar Galactica: CYLON\", \"Transformers: The Ride\"}\n",
    "\n",
    "    # Add is_popular_attraction feature\n",
    "    df_iot['is_popular_attraction'] = df_iot['Attraction'].isin(POPULAR_ATTRACTIONS)\n",
    "\n",
    "    return df_iot\n",
    "\n",
    "# Example usage\n",
    "df_iot = load_iot_data()\n",
    "print(df_iot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking which features are important to predict demand for IOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"Puss In Boots' Giant Journey\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m df_iot = load_iot_data()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m correlation_matrix = \u001b[43mdf_iot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      7\u001b[39m sns.heatmap(correlation_matrix, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m\"\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m\"\u001b[39m, fmt=\u001b[33m\"\u001b[39m\u001b[33m.2f\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\THAI LOW Jin Yang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[39m, in \u001b[36mDataFrame.corr\u001b[39m\u001b[34m(self, method, min_periods, numeric_only)\u001b[39m\n\u001b[32m  11047\u001b[39m cols = data.columns\n\u001b[32m  11048\u001b[39m idx = cols.copy()\n\u001b[32m> \u001b[39m\u001b[32m11049\u001b[39m mat = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m  11051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpearson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m  11052\u001b[39m     correl = libalgos.nancorr(mat, minp=min_periods)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\THAI LOW Jin Yang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[39m, in \u001b[36mDataFrame.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1992\u001b[39m     dtype = np.dtype(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[32m   1995\u001b[39m     result = np.asarray(result, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\THAI LOW Jin Yang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[39m, in \u001b[36mBlockManager.as_array\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1692\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[32m   1696\u001b[39m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\THAI LOW Jin Yang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[39m, in \u001b[36mBlockManager._interleave\u001b[39m\u001b[34m(self, dtype, na_value)\u001b[39m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1752\u001b[39m         arr = blk.get_values(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1753\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m = arr\n\u001b[32m   1754\u001b[39m     itemmask[rl.indexer] = \u001b[32m1\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask.all():\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: \"Puss In Boots' Giant Journey\""
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_iot = load_iot_data()\n",
    "correlation_matrix = df_iot.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainfall                    0.191108\n",
      "Humidity                    0.181672\n",
      "Temperature                 0.175049\n",
      "Guest_Satisfaction_Score    0.172186\n",
      "Average_Queue_Time          0.147287\n",
      "Check_Out_Time              0.070059\n",
      "Check_In_Time               0.062638\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['Guest_Satisfaction_Score', 'Average_Queue_Time', 'Check_In_Time', \n",
    "            'Check_Out_Time', 'Temperature', 'Rainfall', 'Humidity']\n",
    "X = df_iot[features]\n",
    "y = df_iot['Number_of_People_in_Queue']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(file_path=\"../../data/singapore_seasonal_weather.csv\"):\n",
    "    \"\"\"\n",
    "    Fetches or loads seasonal weather data for all months of 2024,\n",
    "    calculates seasonal averages, and saves the result for reuse.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Weather data averaged by season.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"‚úÖ Loaded existing weather data from: {file_path}\")\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    print(\"üì° Fetching weather data from API...\")\n",
    "\n",
    "    base_url = \"https://api.data.gov.sg/v1/environment/\"\n",
    "    weather_types = [\"rainfall\", \"air-temperature\", \"relative-humidity\", \"wind-speed\"]\n",
    "    months = [f\"2024-{str(m).zfill(2)}-15\" for m in range(1, 13)]\n",
    "    month_names = [datetime.strptime(m, \"%Y-%m-%d\").strftime(\"%B\") for m in months]\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for date_str, month_name in zip(months, month_names):\n",
    "        print(f\"Fetching data for: {date_str}\")\n",
    "        daily_data = {\"month\": month_name}\n",
    "\n",
    "        for weather_type in weather_types:\n",
    "            url = f\"{base_url}{weather_type}\"\n",
    "            params = {\"date\": date_str}\n",
    "            response = requests.get(url, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    readings = data[\"items\"][0][\"readings\"]\n",
    "                    avg_value = sum(d[\"value\"] for d in readings) / len(readings)\n",
    "                    daily_data[weather_type] = avg_value\n",
    "                except (KeyError, IndexError):\n",
    "                    print(f\"‚ö†Ô∏è Missing data for {weather_type} on {date_str}\")\n",
    "                    daily_data[weather_type] = None\n",
    "            else:\n",
    "                print(f\"‚ùå Error fetching {weather_type} for {date_str}: {response.status_code}\")\n",
    "                daily_data[weather_type] = None\n",
    "\n",
    "        all_data.append(daily_data)\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Map months to seasons\n",
    "    month_to_season = {\n",
    "        \"January\": \"January - March\", \"February\": \"January - March\", \"March\": \"January - March\",\n",
    "        \"April\": \"April - June\", \"May\": \"April - June\", \"June\": \"April - June\",\n",
    "        \"July\": \"July - September\", \"August\": \"July - September\", \"September\": \"July - September\",\n",
    "        \"October\": \"October - December\", \"November\": \"October - December\", \"December\": \"October - December\"\n",
    "    }\n",
    "    df[\"Season\"] = df[\"month\"].map(month_to_season)\n",
    "\n",
    "    # Average by season\n",
    "    df_seasonal = df.groupby(\"Season\").agg({\n",
    "        \"rainfall\": \"mean\",\n",
    "        \"air-temperature\": \"mean\",\n",
    "        \"relative-humidity\": \"mean\",\n",
    "        \"wind-speed\": \"mean\"\n",
    "    }).reset_index()\n",
    "\n",
    "    df_seasonal.rename(columns={\n",
    "        \"air-temperature\": \"air_temperature\",\n",
    "        \"relative-humidity\": \"relative_humidity\",\n",
    "        \"wind-speed\": \"wind_speed\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Save to disk\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    df_seasonal.to_csv(file_path, index=False)\n",
    "    print(f\"‚úÖ Saved seasonal weather data to: {file_path}\")\n",
    "\n",
    "    return df_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Fetching weather data from API...\n",
      "Fetching data for: 2024-01-15\n",
      "Fetching data for: 2024-02-15\n",
      "Fetching data for: 2024-03-15\n",
      "Fetching data for: 2024-04-15\n",
      "Fetching data for: 2024-05-15\n",
      "Fetching data for: 2024-06-15\n",
      "Fetching data for: 2024-07-15\n",
      "Fetching data for: 2024-08-15\n",
      "Fetching data for: 2024-09-15\n",
      "Fetching data for: 2024-10-15\n",
      "Fetching data for: 2024-11-15\n",
      "Fetching data for: 2024-12-15\n",
      "‚úÖ Saved seasonal weather data to: ../../data/singapore_seasonal_weather.csv\n",
      "               Season  rainfall  air_temperature  relative_humidity  \\\n",
      "0        April - June  0.000000        27.910354          86.727778   \n",
      "1     January - March  0.001093        27.134091          81.434444   \n",
      "2    July - September  0.000000        27.970971          78.282112   \n",
      "3  October - December  0.000000        27.033810          83.870873   \n",
      "\n",
      "   wind_speed  \n",
      "0    2.330833  \n",
      "1    4.568889  \n",
      "2    2.646852  \n",
      "3    2.230736  \n"
     ]
    }
   ],
   "source": [
    "df_weather = fetch_weather_data(\"../../data/singapore_seasonal_weather.csv\")\n",
    "print(df_weather.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets\n",
    "### Merging survey and weather data (to analyse the absence of IOT data to feed into the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_survey_weather_iot(survey_df, weather_df, iot_df=None):\n",
    "    \"\"\"\n",
    "    Merges survey data with seasonal weather data, and appends IoT data if provided.\n",
    "    \n",
    "    Args:\n",
    "        survey_df (pd.DataFrame): Survey data with a 'Season' column.\n",
    "        weather_df (pd.DataFrame): Seasonal weather data with 'Season' column.\n",
    "        iot_df (pd.DataFrame, optional): IoT data (should contain 'Season' column).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined dataset (survey + weather [+ iot if provided]).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Merge survey with weather data\n",
    "    merged_survey = pd.merge(survey_df, weather_df, on='Season', how='left')\n",
    "\n",
    "    if iot_df is None:\n",
    "        return merged_survey\n",
    "\n",
    "    # Ensure 'Season' exists in IoT data\n",
    "    if 'Season' not in iot_df.columns:\n",
    "        print(\"‚ö†Ô∏è 'Season' column missing in IoT data. Assigning season synthetically...\")\n",
    "        if 'Timestamp' in iot_df.columns:\n",
    "            iot_df['Timestamp'] = pd.to_datetime(iot_df['Timestamp'])\n",
    "            month_to_season = {\n",
    "                1: \"January - March\", 2: \"January - March\", 3: \"January - March\",\n",
    "                4: \"April - June\", 5: \"April - June\", 6: \"April - June\",\n",
    "                7: \"July - September\", 8: \"July - September\", 9: \"July - September\",\n",
    "                10: \"October - December\", 11: \"October - December\", 12: \"October - December\"\n",
    "            }\n",
    "            iot_df['Season'] = iot_df['Timestamp'].dt.month.map(month_to_season)\n",
    "        else:\n",
    "            iot_df['Season'] = np.random.choice(\n",
    "                [\"January - March\", \"April - June\", \"July - September\", \"October - December\"],\n",
    "                size=len(iot_df),\n",
    "                p=[0.1, 0.1, 0.4, 0.4]\n",
    "            )\n",
    "\n",
    "    # Merge IoT with weather\n",
    "    merged_iot = pd.merge(iot_df, weather_df, on='Season', how='left')\n",
    "\n",
    "    # Append both datasets (not inner join, preserve all columns)\n",
    "    combined = pd.concat([merged_survey, merged_iot], ignore_index=True, join='outer')\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged dataset without IOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Attraction  Wait_Time          Event  \\\n",
      "0  Sesame Street Spaghetti Space Chase       37.5           None   \n",
      "1                 Revenge of the Mummy       37.5           None   \n",
      "2                 Revenge of the Mummy       37.5           None   \n",
      "3  Sesame Street Spaghetti Space Chase       37.5           None   \n",
      "4                 Revenge of the Mummy       37.5  Special Event   \n",
      "\n",
      "   Guest_Satisfaction_Score Which part of the year did you visit USS?  \\\n",
      "0                      0.50                   Can't recall / Not sure   \n",
      "1                      0.75                   Can't recall / Not sure   \n",
      "2                      0.50                   Can't recall / Not sure   \n",
      "3                      0.75                        October - December   \n",
      "4                      0.25                   Can't recall / Not sure   \n",
      "\n",
      "  Did you purchase the Express Pass? What was the main purpose of your visit?  \\\n",
      "0                                 No                            Family outing   \n",
      "1                                 No                            Family outing   \n",
      "2                                 No                         Social gathering   \n",
      "3                                 No                         Social gathering   \n",
      "4                                 No                         Social gathering   \n",
      "\n",
      "   Who did you visit USS with? Which age group do you belong to?  \\\n",
      "0  Family (including children)                 18 - 24 years old   \n",
      "1         Family (adults only)                 18 - 24 years old   \n",
      "2                      Friends                 18 - 24 years old   \n",
      "3                      Friends                 18 - 24 years old   \n",
      "4                      Friends                 18 - 24 years old   \n",
      "\n",
      "               Season  rainfall  air_temperature  relative_humidity  \\\n",
      "0  October - December       0.0        27.033810          83.870873   \n",
      "1  October - December       0.0        27.033810          83.870873   \n",
      "2    July - September       0.0        27.970971          78.282112   \n",
      "3  October - December       0.0        27.033810          83.870873   \n",
      "4    July - September       0.0        27.970971          78.282112   \n",
      "\n",
      "   wind_speed  \n",
      "0    2.230736  \n",
      "1    2.230736  \n",
      "2    2.646852  \n",
      "3    2.230736  \n",
      "4    2.646852  \n",
      "['Attraction', 'Wait_Time', 'Event', 'Guest_Satisfaction_Score', 'Which part of the year did you visit USS?', 'Did you purchase the Express Pass?', 'What was the main purpose of your visit?', 'Who did you visit USS with?', 'Which age group do you belong to?', 'Season', 'rainfall', 'air_temperature', 'relative_humidity', 'wind_speed']\n"
     ]
    }
   ],
   "source": [
    "df_combined = merge_survey_weather_iot(df_survey, df_weather)\n",
    "print(df_combined.head())\n",
    "print(df_combined.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Merged dataset with IOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Attraction  Wait_Time          Event  \\\n",
      "0  Sesame Street Spaghetti Space Chase       37.5           None   \n",
      "1                 Revenge of the Mummy       37.5           None   \n",
      "2                 Revenge of the Mummy       37.5           None   \n",
      "3  Sesame Street Spaghetti Space Chase       37.5           None   \n",
      "4                 Revenge of the Mummy       37.5  Special Event   \n",
      "\n",
      "   Guest_Satisfaction_Score Which part of the year did you visit USS?  \\\n",
      "0                      0.50                   Can't recall / Not sure   \n",
      "1                      0.75                   Can't recall / Not sure   \n",
      "2                      0.50                   Can't recall / Not sure   \n",
      "3                      0.75                        October - December   \n",
      "4                      0.25                   Can't recall / Not sure   \n",
      "\n",
      "  Did you purchase the Express Pass? What was the main purpose of your visit?  \\\n",
      "0                                 No                            Family outing   \n",
      "1                                 No                            Family outing   \n",
      "2                                 No                         Social gathering   \n",
      "3                                 No                         Social gathering   \n",
      "4                                 No                         Social gathering   \n",
      "\n",
      "   Who did you visit USS with? Which age group do you belong to?  \\\n",
      "0  Family (including children)                 18 - 24 years old   \n",
      "1         Family (adults only)                 18 - 24 years old   \n",
      "2                      Friends                 18 - 24 years old   \n",
      "3                      Friends                 18 - 24 years old   \n",
      "4                      Friends                 18 - 24 years old   \n",
      "\n",
      "               Season  ...  Step_Count  Transaction_Amount  \\\n",
      "0  October - December  ...         NaN                 NaN   \n",
      "1  October - December  ...         NaN                 NaN   \n",
      "2    July - September  ...         NaN                 NaN   \n",
      "3  October - December  ...         NaN                 NaN   \n",
      "4    July - September  ...         NaN                 NaN   \n",
      "\n",
      "   Average_Queue_Time  Number_of_People_in_Queue Temperature Rainfall  \\\n",
      "0                 NaN                        NaN         NaN      NaN   \n",
      "1                 NaN                        NaN         NaN      NaN   \n",
      "2                 NaN                        NaN         NaN      NaN   \n",
      "3                 NaN                        NaN         NaN      NaN   \n",
      "4                 NaN                        NaN         NaN      NaN   \n",
      "\n",
      "  Humidity day_of_week  is_weekend  is_popular_attraction  \n",
      "0      NaN         NaN         NaN                    NaN  \n",
      "1      NaN         NaN         NaN                    NaN  \n",
      "2      NaN         NaN         NaN                    NaN  \n",
      "3      NaN         NaN         NaN                    NaN  \n",
      "4      NaN         NaN         NaN                    NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "['Attraction', 'Wait_Time', 'Event', 'Guest_Satisfaction_Score', 'Which part of the year did you visit USS?', 'Did you purchase the Express Pass?', 'What was the main purpose of your visit?', 'Who did you visit USS with?', 'Which age group do you belong to?', 'Season', 'rainfall', 'air_temperature', 'relative_humidity', 'wind_speed', 'Timestamp', 'Age_Group', 'Gender', 'Loyalty_Member', 'Check_In_Time', 'Check_Out_Time', 'Step_Count', 'Transaction_Amount', 'Average_Queue_Time', 'Number_of_People_in_Queue', 'Temperature', 'Rainfall', 'Humidity', 'day_of_week', 'is_weekend', 'is_popular_attraction']\n"
     ]
    }
   ],
   "source": [
    "df_all_combined = merge_survey_weather_iot(df_survey, df_weather, df_iot)\n",
    "print(df_all_combined.head())\n",
    "print(df_all_combined.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def train_demand_model_flexible(df, target='Number_of_People_in_Queue'):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost model that adapts to the columns available in the dataset,\n",
    "    including fallback handling for missing values due to merged sources.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Merged dataset (survey + weather [+ iot]).\n",
    "        target (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        model (XGBRegressor): Trained model.\n",
    "        metrics (dict): Evaluation results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Full list of possible features (IoT + survey + weather)\n",
    "    potential_features = [\n",
    "        'Season', 'Attraction', 'Wait_Time', 'Guest_Satisfaction_Score',\n",
    "        'rainfall', 'relative_humidity', 'air_temperature',\n",
    "        'Average_Queue_Time', 'Check_In_Time', 'Check_Out_Time'\n",
    "    ]\n",
    "\n",
    "    # --- Filter features that actually exist and are not fully null ---\n",
    "    available_features = [col for col in potential_features if col in df.columns and df[col].notna().any()]\n",
    "    print(f\"üßÆ Using features: {available_features}\")\n",
    "\n",
    "    # --- Drop rows where the target is missing ---\n",
    "    df = df[df[target].notna()]\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"‚ùå No rows with valid target '{target}'.\")\n",
    "\n",
    "    # --- Fill missing values in features ---\n",
    "    df = df[available_features + [target]].copy()\n",
    "    for col in available_features:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].mean())  # Use mean for numeric cols\n",
    "\n",
    "    # --- Encode categoricals ---\n",
    "    for col in ['Season', 'Attraction']:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "    # --- Split data ---\n",
    "    X = df[available_features]\n",
    "    y = df[target]\n",
    "\n",
    "    if len(df) < 5:\n",
    "        raise ValueError(\"‚ùå Not enough samples to split. Need at least 5 rows.\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- Train XGBoost ---\n",
    "    model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    metrics = {\n",
    "        'R¬≤ Score': r2_score(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    print(\"‚úÖ Model trained successfully.\")\n",
    "    print(\"üìä Evaluation:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    return model, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßÆ Using features: ['Season', 'Attraction', 'Wait_Time', 'Guest_Satisfaction_Score', 'rainfall', 'relative_humidity', 'air_temperature', 'Average_Queue_Time', 'Check_In_Time', 'Check_Out_Time']\n",
      "‚úÖ Model trained successfully.\n",
      "üìä Evaluation:\n",
      "R¬≤ Score: 0.0297\n",
      "RMSE: 85.4621\n",
      "MAE: 74.6309\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train_demand_model_flexible(df_all_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
