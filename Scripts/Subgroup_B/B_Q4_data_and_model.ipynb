{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWffbqKmfaxV",
    "outputId": "0a9a612c-ffea-4dc3-8423-7fac68d41835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully read Universal Studios data, 50904 rows\n",
      "Disneyland Reviews:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42656 entries, 0 to 42655\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Review_ID          42656 non-null  int64 \n",
      " 1   Rating             42656 non-null  int64 \n",
      " 2   Year_Month         42656 non-null  object\n",
      " 3   Reviewer_Location  42656 non-null  object\n",
      " 4   Review_Text        42656 non-null  object\n",
      " 5   Branch             42656 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "\n",
      "Universal Studios Reviews:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50904 entries, 0 to 50903\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   reviewer      50904 non-null  object \n",
      " 1   rating        50904 non-null  float64\n",
      " 2   written_date  50904 non-null  object \n",
      " 3   title         50904 non-null  object \n",
      " 4   review_text   50904 non-null  object \n",
      " 5   branch        50904 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "\n",
      "Merged dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93560 entries, 0 to 93559\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   review_id          93560 non-null  int64  \n",
      " 1   rating             93560 non-null  float64\n",
      " 2   date               93560 non-null  object \n",
      " 3   reviewer_location  93560 non-null  object \n",
      " 4   review_text        93560 non-null  object \n",
      " 5   review_title       50904 non-null  object \n",
      " 6   branch             93560 non-null  object \n",
      " 7   park_type          93560 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "   review_id  rating    date     reviewer_location  \\\n",
      "0  670772142     4.0  2019-4             Australia   \n",
      "1  670682799     4.0  2019-5           Philippines   \n",
      "2  670623270     4.0  2019-4  United Arab Emirates   \n",
      "3  670607911     4.0  2019-4             Australia   \n",
      "4  670607296     4.0  2019-4        United Kingdom   \n",
      "\n",
      "                                         review_text review_title  \\\n",
      "0  If you've ever been to Disneyland anywhere you...          NaN   \n",
      "1  Its been a while since d last time we visit HK...          NaN   \n",
      "2  Thanks God it wasn   t too hot or too humid wh...          NaN   \n",
      "3  HK Disneyland is a great compact park. Unfortu...          NaN   \n",
      "4  the location is not in the city, took around 1...          NaN   \n",
      "\n",
      "                branch park_type  \n",
      "0  Disneyland_HongKong    Disney  \n",
      "1  Disneyland_HongKong    Disney  \n",
      "2  Disneyland_HongKong    Disney  \n",
      "3  Disneyland_HongKong    Disney  \n",
      "4  Disneyland_HongKong    Disney  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# datasets\n",
    "filepath = 'data/DisneylandReviews.csv'\n",
    "disney_df = pd.read_csv(filepath, encoding='utf-8', encoding_errors='replace')\n",
    "\n",
    "# try to read uss_df\n",
    "uss_filepath = 'data/universal_studio_branches.csv'\n",
    "try:\n",
    "    # use the new parameter name in pandas 1.4+\n",
    "    uss_df = pd.read_csv(uss_filepath,\n",
    "                         encoding='utf-8',\n",
    "                         encoding_errors='replace',\n",
    "                         engine='python',\n",
    "                         on_bad_lines='skip')  # alternative to error_bad_lines=False\n",
    "except:\n",
    "    try:\n",
    "        # try the old parameter name\n",
    "        uss_df = pd.read_csv(uss_filepath,\n",
    "                             encoding='utf-8',\n",
    "                             encoding_errors='replace',\n",
    "                             engine='python',\n",
    "                             error_bad_lines=False)\n",
    "    except:\n",
    "        # if all above methods fail, try to specify the separator and quote character\n",
    "        uss_df = pd.read_csv(uss_filepath,\n",
    "                             encoding='utf-8',\n",
    "                             encoding_errors='replace',\n",
    "                             engine='python',\n",
    "                             sep=',',\n",
    "                             quoting=3,  # QUOTE_NONE\n",
    "                             escapechar='\\\\')  # use backslash as escape character\n",
    "\n",
    "print(f\"successfully read Universal Studios data, {len(uss_df)} rows\")\n",
    "\n",
    "# basic info\n",
    "print(\"Disneyland Reviews:\")\n",
    "print(disney_df.info())\n",
    "print(\"\\nUniversal Studios Reviews:\")\n",
    "print(uss_df.info())\n",
    "\n",
    "# rename columns and merge datasets\n",
    "disney_renamed = disney_df.rename(columns={\n",
    "    'Review_ID': 'review_id',\n",
    "    'Rating': 'rating',\n",
    "    'Year_Month': 'date',\n",
    "    'Reviewer_Location': 'reviewer_location',\n",
    "    'Review_Text': 'review_text',\n",
    "    'Branch': 'branch'\n",
    "})\n",
    "\n",
    "uss_renamed = uss_df.rename(columns={\n",
    "    'reviewer': 'reviewer_location',\n",
    "    'written_date': 'date',\n",
    "    'title': 'review_title',\n",
    "    'review_text': 'review_text'\n",
    "})\n",
    "\n",
    "# tag label for disney and uss\n",
    "disney_renamed['park_type'] = 'Disney'\n",
    "uss_renamed['park_type'] = 'USS'\n",
    "\n",
    "# add missing columns\n",
    "if 'review_id' not in uss_renamed.columns:\n",
    "    uss_renamed['review_id'] = uss_renamed.index + len(disney_renamed)\n",
    "if 'review_title' not in disney_renamed.columns:\n",
    "    disney_renamed['review_title'] = np.nan\n",
    "\n",
    "# select common columns and merge datasets\n",
    "common_columns = ['review_id', 'rating', 'date', 'reviewer_location', 'review_text', 'review_title', 'branch', 'park_type']\n",
    "disney_common = disney_renamed[common_columns]\n",
    "uss_common = uss_renamed[common_columns]\n",
    "\n",
    "# merge datasets\n",
    "combined_df = pd.concat([disney_common, uss_common], ignore_index=True)\n",
    "\n",
    "# check merged dataset\n",
    "print(\"\\nMerged dataset info:\")\n",
    "print(combined_df.info())\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXjiuB7ekRgM",
    "outputId": "0e2982ce-6b95-436e-b93c-1b79254ac458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before handling missing values: \n",
      "review_id                0\n",
      "rating                   0\n",
      "date                     0\n",
      "reviewer_location        0\n",
      "review_text              0\n",
      "review_title         42656\n",
      "branch                   0\n",
      "park_type                0\n",
      "standardized_date     2613\n",
      "year                  2613\n",
      "month                 2613\n",
      "dtype: int64\n",
      "After handling missing values: \n",
      "review_id               0\n",
      "rating                  0\n",
      "date                    0\n",
      "reviewer_location       0\n",
      "review_text             0\n",
      "review_title            0\n",
      "branch                  0\n",
      "park_type               0\n",
      "standardized_date    2613\n",
      "year                 2613\n",
      "month                2613\n",
      "dtype: int64\n",
      "\n",
      "Negative experience distribution:\n",
      "bad_experience\n",
      "0    51348\n",
      "1    42212\n",
      "Name: count, dtype: int64\n",
      "Negative experience ratio: 45.12%\n"
     ]
    }
   ],
   "source": [
    "# standardize date\n",
    "def standardize_date(date_str):\n",
    "    try:\n",
    "        # try to parse disney format (Year_Month)\n",
    "        if isinstance(date_str, str) and len(date_str.split('-')) == 2:\n",
    "            year, month = date_str.split('-')\n",
    "            return f\"{year}-{month}-01\"\n",
    "        # try to parse uss format\n",
    "        elif isinstance(date_str, str):\n",
    "            return pd.to_datetime(date_str).strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "combined_df['standardized_date'] = combined_df['date'].apply(standardize_date)\n",
    "combined_df['standardized_date'] = pd.to_datetime(combined_df['standardized_date'], errors='coerce')\n",
    "\n",
    "# extract year and month\n",
    "combined_df['year'] = combined_df['standardized_date'].dt.year\n",
    "combined_df['month'] = combined_df['standardized_date'].dt.month\n",
    "\n",
    "# handle missing values\n",
    "print(f\"Before handling missing values: \\n{combined_df.isnull().sum()}\")\n",
    "\n",
    "# fill missing review titles\n",
    "combined_df['review_title'] = combined_df['review_title'].fillna('No Title')\n",
    "\n",
    "# delete rows without review text\n",
    "combined_df = combined_df.dropna(subset=['review_text'])\n",
    "\n",
    "print(f\"After handling missing values: \\n{combined_df.isnull().sum()}\")\n",
    "\n",
    "# convert rating to numeric\n",
    "combined_df['rating'] = pd.to_numeric(combined_df['rating'], errors='coerce')\n",
    "\n",
    "# create negative experience label (rating <= 4 is negative experience)\n",
    "combined_df['bad_experience'] = (combined_df['rating'] <= 4).astype(int)\n",
    "\n",
    "# check the distribution of negative experience\n",
    "print(\"\\nNegative experience distribution:\")\n",
    "print(combined_df['bad_experience'].value_counts())\n",
    "print(f\"Negative experience ratio: {combined_df['bad_experience'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Xkx7gaKLqpCW"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 3. rating trend over time\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m monthly_ratings \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpark_type\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     31\u001b[0m monthly_ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(monthly_ratings[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39massign(day\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   9193\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m   1330\u001b[0m         obj,\n\u001b[1;32m   1331\u001b[0m         keys,\n\u001b[1;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[1;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m   1337\u001b[0m     )\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'year'"
     ]
    }
   ],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# 1. rating distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='rating', hue='park_type', data=combined_df)\n",
    "plt.title('Disney and USS rating distribution')\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('number')\n",
    "plt.savefig('rating_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. rating distribution of different branches\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='branch', y='rating', hue='park_type', data=combined_df)\n",
    "plt.title('rating distribution of different branches')\n",
    "plt.xlabel('branch')\n",
    "plt.ylabel('rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('branch_ratings.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. rating trend over time\n",
    "monthly_ratings = combined_df.groupby(['year', 'month', 'park_type'])['rating'].mean().reset_index()\n",
    "monthly_ratings['date'] = pd.to_datetime(monthly_ratings[['year', 'month']].assign(day=1))\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "for park in monthly_ratings['park_type'].unique():\n",
    "    park_data = monthly_ratings[monthly_ratings['park_type'] == park]\n",
    "    plt.plot(park_data['date'], park_data['rating'], label=park)\n",
    "plt.title('rating trend over time')\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('average rating')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_trend.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. rating difference by different locations\n",
    "top_locations = combined_df['reviewer_location'].value_counts().head(15).index\n",
    "location_df = combined_df[combined_df['reviewer_location'].isin(top_locations)]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='reviewer_location', y='rating', data=location_df)\n",
    "plt.title('rating distribution by different locations')\n",
    "plt.xlabel('reviewer location')\n",
    "plt.ylabel('rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('location_ratings.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. relationship between negative experience and branches\n",
    "plt.figure(figsize=(14, 6))\n",
    "bad_exp_by_branch = combined_df.groupby(['branch', 'park_type'])['bad_experience'].mean().reset_index()\n",
    "sns.barplot(x='branch', y='bad_experience', hue='park_type', data=bad_exp_by_branch)\n",
    "plt.title('negative experience ratio by branches')\n",
    "plt.xlabel('branch')\n",
    "plt.ylabel('negative experience ratio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('bad_experience_by_branch.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXPnVE58rNYG",
    "outputId": "53a70cd7-74ef-42ed-a958-249880b006a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "words most distinguishing in negative reviews:\n",
      "['mins', 'wouldn', 'unfortunately', 'terrible', 'waited', 'smaller', 'customer', 'fast', 'worst', 'smoking', 'having', 'expected', '90', 'need', 'entrance', 'parking', 'lot', 'know', 'limited', 'lack', 'broke', 'number', 'queuing', 'bit', 'went', 'person', 'disappointment', '45', 'maybe', 'hot', 'wasn', 'ridiculous', 'unless', 'probably', 'let', 'left', '30', 'children', 'expect', 'nice', 'open', 'bad', 'prices', 'better', 'pretty', 'service', 'pass', 'average', 'compared', 'like', 'cost', 'said', 'staff', 'paid', 'way', 'overpriced', 'just', 'did', 'attractions', 'waste', 'express', 'ok', 'wait', 'poor', 'think', 'don', 'half', 'rude', 'crowded', 'disappointing', 'didn', 'paris', 'lines', 'price', 'ticket', 'overall', 'pay', 'told', 'quite', 'ride', 'rides', 'tickets', 'queues', 'food', 'waiting', 'small', 'disappointed', 'minutes', 'expensive', 'park', 'queue', 'money', 'hours', 'hour', 'long', 'disney', 'good', 'line', 'closed', 'people']\n",
      "using 9356 samples for BERT embedding visualization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 293/293 [04:27<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# nltk resources for sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# initialize sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 1. identify and use basic text features\n",
    "combined_df['review_length'] = combined_df['review_text'].apply(len)\n",
    "combined_df['word_count'] = combined_df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# 2. sentiment analysis\n",
    "combined_df['sentiment_score'] = combined_df['review_text'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "combined_df['sentiment_negative'] = combined_df['review_text'].apply(lambda x: sia.polarity_scores(str(x))['neg'])\n",
    "combined_df['sentiment_positive'] = combined_df['review_text'].apply(lambda x: sia.polarity_scores(str(x))['pos'])\n",
    "\n",
    "# 3. keyword extraction - use TF-IDF to find common words in negative reviews\n",
    "negative_reviews = combined_df[combined_df['bad_experience'] == 1]['review_text']\n",
    "positive_reviews = combined_df[combined_df['bad_experience'] == 0]['review_text']\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_neg = tfidf.fit_transform(negative_reviews)\n",
    "tfidf_pos = tfidf.transform(positive_reviews)\n",
    "\n",
    "# get feature names\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# calculate the average TF-IDF value of each word in negative reviews\n",
    "neg_tfidf_means = tfidf_neg.mean(axis=0).A1\n",
    "pos_tfidf_means = tfidf_pos.mean(axis=0).A1\n",
    "\n",
    "# calculate the difference value (words more common in negative reviews)\n",
    "diff_means = neg_tfidf_means - pos_tfidf_means\n",
    "\n",
    "# get the top 100 words with the most distinguishing features\n",
    "top_diff_indices = diff_means.argsort()[-100:]\n",
    "top_neg_words = [feature_names[i] for i in top_diff_indices]\n",
    "\n",
    "print(\"\\nwords most distinguishing in negative reviews:\")\n",
    "print(top_neg_words)\n",
    "\n",
    "# 4. create keyword features\n",
    "# to improve efficiency, only use the first 20 keywords\n",
    "top_20_neg_words = top_neg_words[-20:]\n",
    "for word in top_20_neg_words:\n",
    "    combined_df[f'contains_{word}'] = combined_df['review_text'].apply(lambda x: 1 if word.lower() in str(x).lower() else 0)\n",
    "\n",
    "# 5. use BERT for text embedding (use all data)\n",
    "def get_bert_embeddings(texts, batch_size=32):\n",
    "    # ensure texts is a list of strings\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.astype(str).tolist()\n",
    "    else:\n",
    "        texts = [str(text) for text in texts]\n",
    "\n",
    "    # load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # store the embedding vectors\n",
    "    embeddings = []\n",
    "\n",
    "    # process in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        # tokenize and convert to tensor\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # get BERT embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # use the embedding of CLS token\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# use 10% of data for BERT embedding visualization\n",
    "sample_size = max(1000, int(len(combined_df) * 0.1))\n",
    "sample_df = combined_df.sample(sample_size, random_state=42)\n",
    "print(f\"using {sample_size} samples for BERT embedding visualization\")\n",
    "bert_embeddings = get_bert_embeddings(sample_df['review_text'])\n",
    "\n",
    "# reduce the dimensionality of the BERT embeddings for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "bert_2d = pca.fit_transform(bert_embeddings)\n",
    "\n",
    "# create visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(bert_2d[:, 0], bert_2d[:, 1],\n",
    "                     c=sample_df['bad_experience'].values,\n",
    "                     cmap='coolwarm', alpha=0.6)\n",
    "plt.colorbar(scatter, label='negative experience')\n",
    "plt.title('visualization of BERT embeddings')\n",
    "plt.xlabel('PCA dimension 1')\n",
    "plt.ylabel('PCA dimension 2')\n",
    "plt.savefig('bert_embeddings.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ty89EwvB_c7w",
    "outputId": "e79a0f62-8c03-4ab8-fb8f-e5905182e95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "main topics in reviews:\n",
      "topic 1: park, pass, day, ride, rides, time, wait, line, express, fast\n",
      "topic 2: ride, universal, rides, park, potter, harry, studios, great, fun, day\n",
      "topic 3: rides, day, park, great, time, kids, food, place, good, fun\n",
      "topic 4: disney, park, rides, disneyland, parks, paris, time, just, ride, food\n",
      "topic 5: disneyland, disney, park, time, like, place, just, visit, day, world\n",
      "\n",
      "negative experience ratio of each topic:\n",
      "   dominant_topic  bad_experience\n",
      "0               0        0.623487\n",
      "1               1        0.383549\n",
      "2               2        0.340998\n",
      "3               3        0.675401\n",
      "4               4        0.316063\n",
      "\n",
      "training Logistic Regression model...\n",
      "Logistic Regression model evaluation results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73     10232\n",
      "           1       0.68      0.59      0.63      8480\n",
      "\n",
      "    accuracy                           0.69     18712\n",
      "   macro avg       0.69      0.68      0.68     18712\n",
      "weighted avg       0.69      0.69      0.69     18712\n",
      "\n",
      "ROC AUC: 0.7492\n",
      "\n",
      "training Random Forest model...\n",
      "Random Forest model evaluation results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72     10232\n",
      "           1       0.66      0.58      0.62      8480\n",
      "\n",
      "    accuracy                           0.68     18712\n",
      "   macro avg       0.67      0.67      0.67     18712\n",
      "weighted avg       0.67      0.68      0.67     18712\n",
      "\n",
      "ROC AUC: 0.7299\n",
      "\n",
      "training Gradient Boosting model...\n",
      "Gradient Boosting model evaluation results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74     10232\n",
      "           1       0.71      0.57      0.63      8480\n",
      "\n",
      "    accuracy                           0.70     18712\n",
      "   macro avg       0.70      0.69      0.69     18712\n",
      "weighted avg       0.70      0.70      0.69     18712\n",
      "\n",
      "ROC AUC: 0.7580\n",
      "\n",
      "best model: Gradient Boosting\n",
      "ROC AUC: 0.7580\n"
     ]
    }
   ],
   "source": [
    "# 6. topic modeling - use LDA to find topics in reviews\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create document-word matrix\n",
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = cv.fit_transform(combined_df['review_text'])\n",
    "lda_feature_names = cv.get_feature_names_out()  # use a specific variable name\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "# print the top 10 words of each topic\n",
    "print(\"\\nmain topics in reviews:\")\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_words_idx = topic.argsort()[:-11:-1]  # get the top 10 words\n",
    "\n",
    "    # add safety check\n",
    "    safe_indices = [i for i in top_words_idx if i < len(lda_feature_names)]\n",
    "\n",
    "    if not safe_indices:\n",
    "        print(f\"    topic {topic_idx}: No valid words found\")\n",
    "        continue\n",
    "\n",
    "    top_words = [lda_feature_names[i] for i in safe_indices]\n",
    "    print(f\"topic {topic_idx+1}: {', '.join(top_words)}\")\n",
    "\n",
    "# assign topics to each review\n",
    "topic_results = lda.transform(dtm)\n",
    "combined_df['dominant_topic'] = topic_results.argmax(axis=1)\n",
    "\n",
    "# analyze the relationship between topics and negative experience\n",
    "topic_bad_exp = combined_df.groupby('dominant_topic')['bad_experience'].mean().reset_index()\n",
    "print(\"\\nnegative experience ratio of each topic:\")\n",
    "print(topic_bad_exp)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='dominant_topic', y='bad_experience', data=topic_bad_exp)\n",
    "plt.title('negative experience ratio of each topic')\n",
    "plt.xlabel('topic number')\n",
    "plt.ylabel('negative experience ratio')\n",
    "plt.savefig('topic_bad_experience.png')\n",
    "plt.close()\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# prepare features and target variable\n",
    "# selected numeric features\n",
    "numeric_features = ['review_length', 'word_count', 'sentiment_score',\n",
    "                    'sentiment_negative', 'sentiment_positive']\n",
    "\n",
    "# selected categorical features\n",
    "categorical_features = ['branch', 'park_type', 'dominant_topic']\n",
    "\n",
    "# add keyword features (use the first 20 keywords)\n",
    "keyword_features = [f'contains_{word}' for word in top_20_neg_words]\n",
    "\n",
    "# merge all features\n",
    "all_features = numeric_features + categorical_features + keyword_features\n",
    "\n",
    "# prepare data\n",
    "X = combined_df[all_features].copy()\n",
    "y = combined_df['bad_experience']\n",
    "\n",
    "# handle missing values using SimpleImputer\n",
    "# fill numeric features with median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "X[numeric_features] = num_imputer.fit_transform(X[numeric_features])\n",
    "\n",
    "# fill categorical features and keyword features with mode\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "if categorical_features + keyword_features:  # ensure the list is not empty\n",
    "    X[categorical_features + keyword_features] = cat_imputer.fit_transform(X[categorical_features + keyword_features])\n",
    "\n",
    "# split training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create preprocess pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# create model pipeline using logistic regression, random forest and gradient boosting\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ]),\n",
    "    'Gradient Boosting': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\ntraining {name} model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # evaluate\n",
    "    print(f\"{name} model evaluation results:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "\n",
    "    # save results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "\n",
    "# find the best model\n",
    "best_model_name = max(results, key=lambda k: results[k]['roc_auc'])\n",
    "print(f\"\\nbest model: {best_model_name}\")\n",
    "print(f\"ROC AUC: {results[best_model_name]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LX0XpVGKo7I",
    "outputId": "ebd10817-b2f3-4c67-f5ae-f09b72f4caa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 74848, test set size: 18712\n",
      "tokenizing training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:36<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:37<00:00,  1.95s/it]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2339/2339 [24:18<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: 0.4701\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2339/2339 [24:27<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: 0.3985\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1443/2339 [15:05<09:20,  1.60it/s]"
     ]
    }
   ],
   "source": [
    "# BERT model training\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# prepare data\n",
    "texts = combined_df['review_text'].tolist()\n",
    "labels = combined_df['bad_experience'].tolist()\n",
    "\n",
    "# split training and test set\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"training set size: {len(train_texts)}, test set size: {len(test_texts)}\")\n",
    "\n",
    "# load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenize texts - use batch processing to save memory\n",
    "def tokenize_in_batches(texts, batch_size=1000):\n",
    "    # ensure texts is a list of strings\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.astype(str).tolist()\n",
    "    else:\n",
    "        texts = [str(text) for text in texts]\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=128)\n",
    "        all_input_ids.extend(encodings['input_ids'])\n",
    "        all_attention_masks.extend(encodings['attention_mask'])\n",
    "\n",
    "    return {\n",
    "        'input_ids': all_input_ids,\n",
    "        'attention_mask': all_attention_masks\n",
    "    }\n",
    "\n",
    "print(\"tokenizing training set...\")\n",
    "train_encodings = tokenize_in_batches(train_texts)\n",
    "print(\"tokenizing test set...\")\n",
    "test_encodings = tokenize_in_batches(test_texts)\n",
    "\n",
    "# convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(train_labels)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(test_encodings['input_ids']),\n",
    "    torch.tensor(test_encodings['attention_mask']),\n",
    "    torch.tensor(test_labels)\n",
    ")\n",
    "\n",
    "# create data loader - use larger batch size to accelerate training\n",
    "batch_size = 32  # adjust based on GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# set optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# train model\n",
    "model.train()\n",
    "num_epochs = 3  # adjust based on dataset size and time limit\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        # move data to device\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"average loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# evaluate model\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "print(\"\\nBERT model evaluation results:\")\n",
    "print(f\"accuracy: {accuracy_score(true_labels, predictions):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(true_labels, all_probs):.4f}\")\n",
    "print(classification_report(true_labels, predictions))\n",
    "\n",
    "# Complaint Severity Analysis\n",
    "def classify_complaint_severity(text, rating, sentiment_neg, sentiment_score):\n",
    "    \"\"\"\n",
    "    classify complaint severity based on review text, rating and sentiment analysis\n",
    "\n",
    "    returns:\n",
    "    0 - no complaint\n",
    "    1 - mild complaint\n",
    "    2 - moderate complaint\n",
    "    3 - severe complaint\n",
    "    \"\"\"\n",
    "    if rating > 4:  # high rating is not usually a complaint\n",
    "        return 0\n",
    "\n",
    "    # use sentiment analysis\n",
    "    neg_score = sentiment_neg\n",
    "    compound_score = sentiment_score\n",
    "\n",
    "    # determine severity based on rating, negative sentiment and compound sentiment\n",
    "    if rating <= 2 and (neg_score > 0.5 or compound_score < -0.5):\n",
    "        return 3  # severe complaint\n",
    "    elif rating <= 3 and (neg_score > 0.3 or compound_score < -0.3):\n",
    "        return 2  # moderate complaint\n",
    "    elif rating <= 4:\n",
    "        return 1  # mild complaint\n",
    "    else:\n",
    "        return 0  # no complaint\n",
    "\n",
    "# apply complaint severity classification\n",
    "combined_df['complaint_severity'] = combined_df.apply(\n",
    "    lambda row: classify_complaint_severity(\n",
    "        row['review_text'],\n",
    "        row['rating'],\n",
    "        row['sentiment_negative'],\n",
    "        row['sentiment_score']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# analyze complaint severity distribution\n",
    "severity_counts = combined_df['complaint_severity'].value_counts().sort_index()\n",
    "print(\"\\ncomplaint severity distribution:\")\n",
    "print(severity_counts)\n",
    "print(f\"complaint ratio: {(combined_df['complaint_severity'] > 0).mean():.2%}\")\n",
    "\n",
    "# visualize complaint severity distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='complaint_severity', hue='park_type', data=combined_df)\n",
    "plt.title('complaint severity distribution')\n",
    "plt.xlabel('severity level (0=no complaint, 3=severe complaint)')\n",
    "plt.ylabel('number')\n",
    "plt.savefig('complaint_severity_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Recovery Strategy\n",
    "def recommend_recovery_action(severity, topic, branch):\n",
    "    \"\"\"\n",
    "    recommend recovery strategy based on complaint severity, topic and branch\n",
    "    \"\"\"\n",
    "    recovery_actions = {\n",
    "        0: \"no action needed\",\n",
    "        1: \"send apology email and provide small discount coupon\",\n",
    "        2: \"customer service team to contact and provide partial refund or free upgrade\",\n",
    "        3: \"management intervention, full refund or free re-visit, and root cause analysis\"\n",
    "    }\n",
    "\n",
    "    # customize recovery strategy based on topic (assume topic meaning as follows)\n",
    "    topic_specific = {\n",
    "        0: \"facility maintenance and cleaning\",\n",
    "        1: \"employee training and customer service\",\n",
    "        2: \"queue and capacity management\",\n",
    "        3: \"food quality and variety\",\n",
    "        4: \"information provision and expectation management\"\n",
    "    }\n",
    "\n",
    "    base_action = recovery_actions[severity]\n",
    "    if severity > 0 and topic in topic_specific:\n",
    "        return f\"{base_action}, focus on {topic_specific[topic]}\"\n",
    "    return base_action\n",
    "\n",
    "combined_df['recommended_action'] = combined_df.apply(\n",
    "    lambda row: recommend_recovery_action(\n",
    "        row['complaint_severity'],\n",
    "        row['dominant_topic'],\n",
    "        row['branch']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# analyze recommended recovery strategy distribution\n",
    "action_counts = combined_df['recommended_action'].value_counts()\n",
    "print(\"\\nrecommended recovery strategy distribution:\")\n",
    "print(action_counts)\n",
    "\n",
    "# summarize results\n",
    "print(\"\\ncomplaint prediction and recovery analysis summary:\")\n",
    "print(f\"1. total comments: {len(combined_df)}\")\n",
    "print(f\"2. negative experience ratio: {combined_df['bad_experience'].mean():.2%}\")\n",
    "print(f\"3. complaint severity distribution: {severity_counts.to_dict()}\")\n",
    "print(f\"4. best prediction model: {best_model_name}, ROC AUC: {results[best_model_name]['roc_auc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
